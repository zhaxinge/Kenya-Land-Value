{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5168e97-9a77-4348-8d2f-dd9241fc8be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import geopandas as gpd\n",
    "RASTERIO_BEST_PRACTICES = dict(  # See https://github.com/pangeo-data/cog-best-practices\n",
    "    CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\",\n",
    "    GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "    AWS_NO_SIGN_REQUEST=\"YES\",\n",
    "    GDAL_MAX_RAW_BLOCK_CACHE_SIZE=\"200000000\",\n",
    "    GDAL_SWATH_SIZE=\"200000000\",\n",
    "    VSI_CURL_CACHE_SIZE=\"200000000\",\n",
    ")\n",
    "os.environ.update(RASTERIO_BEST_PRACTICES)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import rasterio\n",
    "import rasterio.warp\n",
    "import rasterio.mask\n",
    "import shapely.geometry\n",
    "import geopandas\n",
    "import dask_geopandas\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from dask.distributed import Client\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=LinAlgWarning, module=\"sklearn\")\n",
    "\n",
    "import pystac_client\n",
    "import planetary_computer as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc887083-f590-448a-b4fd-2b0089445ee7",
   "metadata": {},
   "source": [
    "# Function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f992757-edcb-421f-988d-d4aca079b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(input_img, model, device):\n",
    "    \"\"\"Helper method for running an image patch through the model.\n",
    "\n",
    "    Args:\n",
    "        input_img (np.ndarray): Image in (C x H x W) format with a dtype of uint8.\n",
    "        model (torch.nn.Module): Feature extractor network\n",
    "    \"\"\"\n",
    "    assert len(input_img.shape) == 1\n",
    "    input_img = torch.from_numpy(input_img / 255.0).float()\n",
    "    input_img = input_img.to(device)\n",
    "    with torch.no_grad():\n",
    "        feats = model(input_img.unsqueeze(0)).cpu().numpy()\n",
    "    return feats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78f1c4-0c04-45c0-b970-0584a6452019",
   "metadata": {},
   "source": [
    "# RCF RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8b8bc3-0001-4c56-b7aa-efc4188cba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCF(nn.Module):\n",
    "    \"\"\"A model for extracting Random Convolution Features (RCF) from input imagery.\"\"\"\n",
    "\n",
    "    def __init__(self, num_features=16, kernel_size=3, num_input_channels=1):\n",
    "        super(RCF, self).__init__()\n",
    "\n",
    "        # We create `num_features / 2` filters so require `num_features` to be divisible by 2\n",
    "        assert num_features % 2 == 0\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            num_input_channels,\n",
    "            num_features // 2,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=1.0)\n",
    "        nn.init.constant_(self.conv1.bias, -1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1a = F.relu(self.conv1(x), inplace=True)\n",
    "        x1b = F.relu(-self.conv1(x), inplace=True)\n",
    "\n",
    "        x1a = F.adaptive_avg_pool2d(x1a, (1, 1)).squeeze()\n",
    "        x1b = F.adaptive_avg_pool2d(x1b, (1, 1)).squeeze()\n",
    "\n",
    "        if len(x1a.shape) == 1:  # case where we passed a single input\n",
    "            return torch.cat((x1a, x1b), dim=0)\n",
    "        elif len(x1a.shape) == 2:  # case where we passed a batch of > 1 inputs\n",
    "            return torch.cat((x1a, x1b), dim=1)\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4677b0a0-15c5-4983-9081-9139dc61381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(points, num_images_per_point=1):\n",
    "    \"\"\"\n",
    "    Find STAC items for points in the `points` DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : geopandas.GeoDataFrame\n",
    "        A GeoDataFrame\n",
    "    num_images_per_point : int\n",
    "        Number of STAC items to retrieve for each point\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        A new geopandas.GeoDataFrame with a `stac_items` column containing a list of\n",
    "        STAC items that cover each point.\n",
    "    \"\"\"\n",
    "    intersects = shapely.geometry.mapping(points.unary_union.convex_hull)\n",
    "\n",
    "    search_start = \"2017-01-01\"\n",
    "    search_end = \"2018-12-31\"\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # The time frame in which we search for non-cloudy imagery\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        intersects=intersects,\n",
    "        datetime=[search_start, search_end],\n",
    "        query={\"eo:cloud_cover\": {\"lt\": 20}},\n",
    "        limit=100,\n",
    "    )\n",
    "    ic = search.get_all_items_as_dict()\n",
    "    #for key, value in ic.iteritems():\n",
    "       # print (key, value)\n",
    "\n",
    "    num_search_results = len(ic[\"features\"])\n",
    "    print(\"Number of search results:\", num_search_results)\n",
    "\n",
    "    features = ic[\"features\"]\n",
    "    features_d = {item[\"id\"]: item for item in features}\n",
    "    print(features_d)\n",
    "\n",
    "    data = {\n",
    "        \"eo:cloud_cover\": [],\n",
    "        \"geometry\": [],\n",
    "    }\n",
    "\n",
    "    index = []\n",
    "\n",
    "    for item in features:\n",
    "        data[\"eo:cloud_cover\"].append(item[\"properties\"][\"eo:cloud_cover\"])\n",
    "        data[\"geometry\"].append(shapely.geometry.shape(item[\"geometry\"]))\n",
    "        index.append(item[\"id\"])\n",
    "\n",
    "    items = geopandas.GeoDataFrame(data, index=index, geometry=\"geometry\").sort_values(\n",
    "        \"eo:cloud_cover\"\n",
    "    )\n",
    "    point_list = points.geometry.tolist()\n",
    "\n",
    "    point_items = []\n",
    "    for point in point_list:\n",
    "        covered_by = items[items.covers(point)]\n",
    "        if len(covered_by):\n",
    "            stac_items = [\n",
    "                features_d[item_id]\n",
    "                for item_id in covered_by.index[:num_images_per_point]\n",
    "            ]\n",
    "            point_items.append(stac_items)\n",
    "        else:\n",
    "            # There weren't any scenes matching our conditions for this point (too cloudy)\n",
    "            point_items.append([])\n",
    "\n",
    "    return points.assign(stac_item=point_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d66bac7-e0b5-4e36-bafe-1e2c9b30680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, points, fns, buffer=500):\n",
    "        self.points = points\n",
    "        self.fns = fns\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.points.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        lon, lat = self.points[idx]\n",
    "        fn = self.fns[idx]\n",
    "\n",
    "        if fn is None:\n",
    "            return None\n",
    "        else:\n",
    "            point_geom = shapely.geometry.mapping(shapely.geometry.Point(lon, lat))\n",
    "\n",
    "            with rasterio.Env():\n",
    "                with rasterio.open(fn, \"r\") as f:\n",
    "                    point_geom = rasterio.warp.transform_geom(\n",
    "                        \"epsg:4326\", f.crs.to_string(), point_geom\n",
    "                    )\n",
    "                    point_shape = shapely.geometry.shape(point_geom)\n",
    "                    mask_shape = point_shape.buffer(self.buffer).envelope\n",
    "                    mask_geom = shapely.geometry.mapping(mask_shape)\n",
    "                    try:\n",
    "                        out_image, out_transform = rasterio.mask.mask(\n",
    "                            f, [mask_geom], crop=True\n",
    "                        )\n",
    "                    except ValueError as e:\n",
    "                        if \"Input shapes do not overlap raster.\" in str(e):\n",
    "                            return None\n",
    "\n",
    "            out_image = out_image / 255.0\n",
    "            out_image = torch.from_numpy(out_image).float()\n",
    "            return out_image\n",
    "\n",
    "def extract_features(train_dataset, model, num_features):\n",
    "    dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=os.cpu_count() * 2,\n",
    "        collate_fn=lambda x: x,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    x_train = np.zeros((train_dataset.points.shape[0], num_features), dtype=float)\n",
    "\n",
    "    tic = time.time()\n",
    "    i = 0\n",
    "\n",
    "    for images in dataloader:\n",
    "        for image in images:\n",
    "            if image is not None:\n",
    "                # A full image should be ~101x101 pixels (i.e. ~1km^2 at a 10m/px spatial\n",
    "                # resolution), however we can receive smaller images if an input point\n",
    "                # happens to be at the edge of a S2 scene (a literal edge case). To deal\n",
    "                # with these (edge) cases we crudely drop all images where the spatial\n",
    "                # dimensions aren't both greater than 20 pixels.\n",
    "                if image.shape[1] >= 20 and image.shape[2] >= 20:\n",
    "                    image = image.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                    x_train[i] = feats\n",
    "                else:\n",
    "                    # this happens if the point is close to the edge of a scene\n",
    "                    # (one or both of the spatial dimensions of the image are very small)\n",
    "                    pass\n",
    "            else:\n",
    "                pass  # this happens if we do not find a S2 scene for some point\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(\n",
    "                    f\"{i}/{train_dataset.points.shape[0]} -- {i / train_dataset.points.shape[0] * 100:0.2f}%\"\n",
    "                    + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                )\n",
    "                tic = time.time()\n",
    "            i += 1\n",
    "\n",
    "    return x_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dec7fe-83cf-4c01-8bd3-01c318e2c477",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e994f5-704e-40c4-a934-f7d0b42dc942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>houseprice</th>\n",
       "      <th>City</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>153,63</td>\n",
       "      <td>35.253528</td>\n",
       "      <td>0.461746</td>\n",
       "      <td>0.064764</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>POINT (35.25353 0.46175)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>153,77</td>\n",
       "      <td>35.266255</td>\n",
       "      <td>0.461746</td>\n",
       "      <td>0.086711</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>POINT (35.26626 0.46175)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>152,58</td>\n",
       "      <td>35.248983</td>\n",
       "      <td>0.462655</td>\n",
       "      <td>0.167129</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>POINT (35.24898 0.46266)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>152,72</td>\n",
       "      <td>35.261710</td>\n",
       "      <td>0.462655</td>\n",
       "      <td>1.091892</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>POINT (35.26171 0.46266)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>151,53</td>\n",
       "      <td>35.244437</td>\n",
       "      <td>0.463564</td>\n",
       "      <td>0.745180</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>POINT (35.24444 0.46356)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>27,66</td>\n",
       "      <td>37.067096</td>\n",
       "      <td>-1.025716</td>\n",
       "      <td>7.017600</td>\n",
       "      <td>Thika</td>\n",
       "      <td>POINT (37.06710 -1.02572)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>27,78</td>\n",
       "      <td>37.078005</td>\n",
       "      <td>-1.025716</td>\n",
       "      <td>7.017600</td>\n",
       "      <td>Thika</td>\n",
       "      <td>POINT (37.07800 -1.02572)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>26,72</td>\n",
       "      <td>37.072550</td>\n",
       "      <td>-1.024807</td>\n",
       "      <td>5.070685</td>\n",
       "      <td>Thika</td>\n",
       "      <td>POINT (37.07255 -1.02481)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>25,66</td>\n",
       "      <td>37.067096</td>\n",
       "      <td>-1.023898</td>\n",
       "      <td>1.713330</td>\n",
       "      <td>Thika</td>\n",
       "      <td>POINT (37.06710 -1.02390)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>25,78</td>\n",
       "      <td>37.078005</td>\n",
       "      <td>-1.023898</td>\n",
       "      <td>1.713330</td>\n",
       "      <td>Thika</td>\n",
       "      <td>POINT (37.07800 -1.02390)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4533 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID        lon       lat  houseprice     City  \\\n",
       "Unnamed: 0                                                     \n",
       "243         153,63  35.253528  0.461746    0.064764  Eldoret   \n",
       "244         153,77  35.266255  0.461746    0.086711  Eldoret   \n",
       "254         152,58  35.248983  0.462655    0.167129  Eldoret   \n",
       "255         152,72  35.261710  0.462655    1.091892  Eldoret   \n",
       "265         151,53  35.244437  0.463564    0.745180  Eldoret   \n",
       "...            ...        ...       ...         ...      ...   \n",
       "1573         27,66  37.067096 -1.025716    7.017600    Thika   \n",
       "1574         27,78  37.078005 -1.025716    7.017600    Thika   \n",
       "1590         26,72  37.072550 -1.024807    5.070685    Thika   \n",
       "1606         25,66  37.067096 -1.023898    1.713330    Thika   \n",
       "1607         25,78  37.078005 -1.023898    1.713330    Thika   \n",
       "\n",
       "                             geometry  \n",
       "Unnamed: 0                             \n",
       "243          POINT (35.25353 0.46175)  \n",
       "244          POINT (35.26626 0.46175)  \n",
       "254          POINT (35.24898 0.46266)  \n",
       "255          POINT (35.26171 0.46266)  \n",
       "265          POINT (35.24444 0.46356)  \n",
       "...                               ...  \n",
       "1573        POINT (37.06710 -1.02572)  \n",
       "1574        POINT (37.07800 -1.02572)  \n",
       "1590        POINT (37.07255 -1.02481)  \n",
       "1606        POINT (37.06710 -1.02390)  \n",
       "1607        POINT (37.07800 -1.02390)  \n",
       "\n",
       "[4533 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "\n",
    "    \"https://drive.google.com/uc?export=download&id=1vaZxJap_x1iyf-ytkDo13Dy_7ETdWsO3\",  # noqa: E501\n",
    "    index_col=0,\n",
    "    na_values=[0,-999]\n",
    ").dropna()\n",
    "points = df[[\"lon\", \"lat\"]]\n",
    "houseprice = df[\"houseprice\"]\n",
    "\n",
    "gdf = geopandas.GeoDataFrame(df, geometry=geopandas.points_from_xy(df.lon, df.lat))\n",
    "gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3efead7d-5245-4942-ac5f-0dbc0781d131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>houseprice</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eldoret</th>\n",
       "      <td>590</td>\n",
       "      <td>590</td>\n",
       "      <td>590</td>\n",
       "      <td>590</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embu</th>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garissa</th>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kakamega</th>\n",
       "      <td>411</td>\n",
       "      <td>411</td>\n",
       "      <td>411</td>\n",
       "      <td>411</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kericho</th>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kisumu</th>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kitui</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Machakos</th>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malindi</th>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mombasa</th>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nairobi</th>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naivasha</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nakuru</th>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nyeri</th>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thika</th>\n",
       "      <td>497</td>\n",
       "      <td>497</td>\n",
       "      <td>497</td>\n",
       "      <td>497</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  lon  lat  houseprice  geometry\n",
       "City                                         \n",
       "Eldoret   590  590  590         590       590\n",
       "Embu      329  329  329         329       329\n",
       "Garissa   275  275  275         275       275\n",
       "Kakamega  411  411  411         411       411\n",
       "Kericho   244  244  244         244       244\n",
       "Kisumu    167  167  167         167       167\n",
       "Kitui     106  106  106         106       106\n",
       "Machakos  264  264  264         264       264\n",
       "Malindi   204  204  204         204       204\n",
       "Mombasa   324  324  324         324       324\n",
       "Nairobi   348  348  348         348       348\n",
       "Naivasha   96   96   96          96        96\n",
       "Nakuru    275  275  275         275       275\n",
       "Nyeri     403  403  403         403       403\n",
       "Thika     497  497  497         497       497"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.groupby('City').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e75de9-c4a3-4dca-9e06-09b2715d2003",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a8b92b-a356-4996-a3f2-60ab8c98d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPARTITIONS = 250\n",
    "\n",
    "ddf = dask_geopandas.from_geopandas(gdf, npartitions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3820c07d-2d3d-48cf-a949-b1975a83ee45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user/zhaxinge@upenn.edu/proxy/8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2.86 s, sys: 2.74 s, total: 5.6 s\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with Client(n_workers=16) as client:\n",
    "    print(client.dashboard_link)\n",
    "    meta = ddf._meta.assign(stac_item=[])\n",
    "    df2 = ddf.map_partitions(query, meta=meta).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae3a975b-edaa-41b5-8430-91617d3c97f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "light = pd.read_csv(\n",
    "    \"https://drive.google.com/uc?export=download&id=1Xg3RrqW4YJVJqBXWHCX-hoNqnbBq_pIn\",  # noqa: E501, this link to the Google drive contains the light data\n",
    "    #index_col=0,\n",
    "    na_values=[0,-999]\n",
    ").dropna()\n",
    "ldf = gpd.GeoDataFrame(light, geometry=geopandas.points_from_xy(light.lon, light.lat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab47e25-fece-4a30-9ffb-57f8a2b1c8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16291"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f962081-9d72-4fc9-8522-e620ddd7b565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_left</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>houseprice</th>\n",
       "      <th>City</th>\n",
       "      <th>geometry</th>\n",
       "      <th>stac_item</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID_right</th>\n",
       "      <th>nightlight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>246,90</td>\n",
       "      <td>39.999240</td>\n",
       "      <td>-3.367984</td>\n",
       "      <td>0.129686</td>\n",
       "      <td>Malindi</td>\n",
       "      <td>POINT (39.99924 -3.36798)</td>\n",
       "      <td>[{'id': 'S2B_MSIL2A_20180307T072739_R049_T37MF...</td>\n",
       "      <td>166</td>\n",
       "      <td>246,90</td>\n",
       "      <td>1.328667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>240,99</td>\n",
       "      <td>37.246460</td>\n",
       "      <td>-1.593632</td>\n",
       "      <td>0.338897</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>POINT (37.24646 -1.59363)</td>\n",
       "      <td>[{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...</td>\n",
       "      <td>167</td>\n",
       "      <td>240,99</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>244,95</td>\n",
       "      <td>40.003786</td>\n",
       "      <td>-3.366168</td>\n",
       "      <td>2.258490</td>\n",
       "      <td>Malindi</td>\n",
       "      <td>POINT (40.00379 -3.36617)</td>\n",
       "      <td>[{'id': 'S2B_MSIL2A_20180307T072739_R049_T37MF...</td>\n",
       "      <td>181</td>\n",
       "      <td>244,95</td>\n",
       "      <td>1.587732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>234,105</td>\n",
       "      <td>39.637599</td>\n",
       "      <td>-4.118565</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>Mombasa</td>\n",
       "      <td>POINT (39.63760 -4.11856)</td>\n",
       "      <td>[{'id': 'S2B_MSIL2A_20180605T072609_R049_T37ME...</td>\n",
       "      <td>183</td>\n",
       "      <td>234,105</td>\n",
       "      <td>1.352132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>237,90</td>\n",
       "      <td>37.238278</td>\n",
       "      <td>-1.590905</td>\n",
       "      <td>1.127589</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>POINT (37.23828 -1.59091)</td>\n",
       "      <td>[{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...</td>\n",
       "      <td>190</td>\n",
       "      <td>237,90</td>\n",
       "      <td>0.080019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>27,126</td>\n",
       "      <td>39.656690</td>\n",
       "      <td>-3.930847</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>Mombasa</td>\n",
       "      <td>POINT (39.65669 -3.93085)</td>\n",
       "      <td>[{'id': 'S2B_MSIL2A_20180605T072609_R049_T37ME...</td>\n",
       "      <td>1802</td>\n",
       "      <td>27,126</td>\n",
       "      <td>0.266560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>29,69</td>\n",
       "      <td>37.219187</td>\n",
       "      <td>-1.401879</td>\n",
       "      <td>0.219142</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>POINT (37.21919 -1.40188)</td>\n",
       "      <td>[{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...</td>\n",
       "      <td>1807</td>\n",
       "      <td>29,69</td>\n",
       "      <td>0.039606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>28,75</td>\n",
       "      <td>37.224642</td>\n",
       "      <td>-1.400970</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>POINT (37.22464 -1.40097)</td>\n",
       "      <td>[{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...</td>\n",
       "      <td>1815</td>\n",
       "      <td>28,75</td>\n",
       "      <td>0.021165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>27,54</td>\n",
       "      <td>37.205551</td>\n",
       "      <td>-1.400061</td>\n",
       "      <td>0.178383</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>POINT (37.20555 -1.40006)</td>\n",
       "      <td>[{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...</td>\n",
       "      <td>1822</td>\n",
       "      <td>27,54</td>\n",
       "      <td>0.027492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>26,60</td>\n",
       "      <td>37.211005</td>\n",
       "      <td>-1.399153</td>\n",
       "      <td>0.176456</td>\n",
       "      <td>Machakos</td>\n",
       "      <td>POINT (37.21101 -1.39915)</td>\n",
       "      <td>[{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...</td>\n",
       "      <td>1830</td>\n",
       "      <td>26,60</td>\n",
       "      <td>0.076563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3637 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_left        lon       lat  houseprice      City  \\\n",
       "Unnamed: 0                                                       \n",
       "166          246,90  39.999240 -3.367984    0.129686   Malindi   \n",
       "167          240,99  37.246460 -1.593632    0.338897  Machakos   \n",
       "181          244,95  40.003786 -3.366168    2.258490   Malindi   \n",
       "183         234,105  39.637599 -4.118565    0.003528   Mombasa   \n",
       "190          237,90  37.238278 -1.590905    1.127589  Machakos   \n",
       "...             ...        ...       ...         ...       ...   \n",
       "1802         27,126  39.656690 -3.930847    0.054200   Mombasa   \n",
       "1807          29,69  37.219187 -1.401879    0.219142  Machakos   \n",
       "1815          28,75  37.224642 -1.400970    0.003344  Machakos   \n",
       "1822          27,54  37.205551 -1.400061    0.178383  Machakos   \n",
       "1830          26,60  37.211005 -1.399153    0.176456  Machakos   \n",
       "\n",
       "                             geometry  \\\n",
       "Unnamed: 0                              \n",
       "166         POINT (39.99924 -3.36798)   \n",
       "167         POINT (37.24646 -1.59363)   \n",
       "181         POINT (40.00379 -3.36617)   \n",
       "183         POINT (39.63760 -4.11856)   \n",
       "190         POINT (37.23828 -1.59091)   \n",
       "...                               ...   \n",
       "1802        POINT (39.65669 -3.93085)   \n",
       "1807        POINT (37.21919 -1.40188)   \n",
       "1815        POINT (37.22464 -1.40097)   \n",
       "1822        POINT (37.20555 -1.40006)   \n",
       "1830        POINT (37.21101 -1.39915)   \n",
       "\n",
       "                                                    stac_item  Unnamed: 0  \\\n",
       "Unnamed: 0                                                                  \n",
       "166         [{'id': 'S2B_MSIL2A_20180307T072739_R049_T37MF...         166   \n",
       "167         [{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...         167   \n",
       "181         [{'id': 'S2B_MSIL2A_20180307T072739_R049_T37MF...         181   \n",
       "183         [{'id': 'S2B_MSIL2A_20180605T072609_R049_T37ME...         183   \n",
       "190         [{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...         190   \n",
       "...                                                       ...         ...   \n",
       "1802        [{'id': 'S2B_MSIL2A_20180605T072609_R049_T37ME...        1802   \n",
       "1807        [{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...        1807   \n",
       "1815        [{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...        1815   \n",
       "1822        [{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...        1822   \n",
       "1830        [{'id': 'S2A_MSIL2A_20180114T075201_R092_T37MC...        1830   \n",
       "\n",
       "           ID_right  nightlight  \n",
       "Unnamed: 0                       \n",
       "166          246,90    1.328667  \n",
       "167          240,99    0.000379  \n",
       "181          244,95    1.587732  \n",
       "183         234,105    1.352132  \n",
       "190          237,90    0.080019  \n",
       "...             ...         ...  \n",
       "1802         27,126    0.266560  \n",
       "1807          29,69    0.039606  \n",
       "1815          28,75    0.021165  \n",
       "1822          27,54    0.027492  \n",
       "1830          26,60    0.076563  \n",
       "\n",
       "[3637 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "join = gpd.sjoin(df2,ldf, how=\"inner\", predicate='intersects')\n",
    "column_mapping = {\n",
    "    'lon_left': 'lon',\n",
    "    'lat_left': 'lat',\n",
    "    'City_left': 'City', # change\n",
    "}\n",
    "\n",
    "join = join.rename(columns=column_mapping).drop(columns = ['index_right','lat_right', 'lon_right','City_right'])\n",
    "\n",
    "\n",
    "join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50196928-221d-4342-a1b2-d620325b5db8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "305ff939-c5ca-4d81-b027-03b3c5b18a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomRGBNDataset(Dataset):\n",
    "    def __init__(self,points,fns_rgb,fns_n):\n",
    "        self.rgb_dataset = CustomDataset(points, fns_rgb)\n",
    "        self.nir_dataset = CustomDataset(points, fns_n)\n",
    "        self.points = points\n",
    "        assert len(self.rgb_dataset)==len(self.nir_dataset)\n",
    "        \n",
    "        self.length=len(self.rgb_dataset)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.cat([self.rgb_dataset[idx], self.nir_dataset[idx]],dim=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "791938b3-1277-4582-a52e-4a9afc6d5733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching the planetary database for the related urls\n",
    "\n",
    "df3 = join.dropna(subset=[\"stac_item\"])\n",
    "\n",
    "#Three channel\n",
    "matching_urls = [\n",
    "    pc.sign(item[0][\"assets\"][\"visual\"][\"href\"]) for item in df3.stac_item\n",
    "] \n",
    "#NIR channel\n",
    "matching_nir = [\n",
    "    pc.sign(item[0][\"assets\"]['B08'][\"href\"]) for item in df3.stac_item\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc5318",
   "metadata": {},
   "source": [
    "df4 for the light dataset: there are two types of light datasets here are the extracted data from the mosaic methods, one for the data from the direct nightlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['ID', 'lon', 'lat', 'houseprice', 'City', 'geometry', 'stac_item']\n",
    "selected_columns = [col for col in df3.columns if col not in columns_to_exclude]\n",
    "\n",
    "df4 = df3[selected_columns]\n",
    "df4 = df4 [['nightlight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293cd48a-fc49-4652-8693-0a79c44a481e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3344 -- 0.00% -- 1.59 seconds\n",
      "1000/3344 -- 29.90% -- 2.97 seconds\n",
      "2000/3344 -- 59.81% -- 3.24 seconds\n",
      "3000/3344 -- 89.71% -- 2.87 seconds\n",
      "0/3344 -- 0.00% -- 0.65 seconds\n",
      "1000/3344 -- 29.90% -- 4.20 seconds\n",
      "2000/3344 -- 59.81% -- 4.25 seconds\n",
      "3000/3344 -- 89.71% -- 3.92 seconds\n",
      "0/293 -- 0.00% -- 0.43 seconds\n",
      "0/293 -- 0.00% -- 0.38 seconds\n",
      "(3344, 384)\n",
      "(3344, 256)\n",
      "(3344,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garissa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3373 -- 0.00% -- 0.78 seconds\n",
      "1000/3373 -- 29.65% -- 2.92 seconds\n",
      "2000/3373 -- 59.29% -- 2.93 seconds\n",
      "3000/3373 -- 88.94% -- 3.25 seconds\n",
      "0/3373 -- 0.00% -- 0.65 seconds\n",
      "1000/3373 -- 29.65% -- 3.93 seconds\n",
      "2000/3373 -- 59.29% -- 3.85 seconds\n",
      "3000/3373 -- 88.94% -- 3.94 seconds\n",
      "0/264 -- 0.00% -- 0.42 seconds\n",
      "0/264 -- 0.00% -- 0.40 seconds\n",
      "(3373, 384)\n",
      "(3373, 256)\n",
      "(3373,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kakamega\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3226 -- 0.00% -- 0.72 seconds\n",
      "1000/3226 -- 31.00% -- 2.90 seconds\n",
      "2000/3226 -- 62.00% -- 2.97 seconds\n",
      "3000/3226 -- 92.99% -- 2.75 seconds\n",
      "0/3226 -- 0.00% -- 0.63 seconds\n",
      "1000/3226 -- 31.00% -- 3.67 seconds\n",
      "2000/3226 -- 62.00% -- 4.16 seconds\n",
      "3000/3226 -- 92.99% -- 3.97 seconds\n",
      "0/411 -- 0.00% -- 0.40 seconds\n",
      "0/411 -- 0.00% -- 0.38 seconds\n",
      "(3226, 384)\n",
      "(3226, 256)\n",
      "(3226,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kericho\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3405 -- 0.00% -- 0.69 seconds\n",
      "1000/3405 -- 29.37% -- 3.03 seconds\n",
      "2000/3405 -- 58.74% -- 2.89 seconds\n",
      "3000/3405 -- 88.11% -- 2.89 seconds\n",
      "0/3405 -- 0.00% -- 0.65 seconds\n",
      "1000/3405 -- 29.37% -- 3.87 seconds\n",
      "2000/3405 -- 58.74% -- 3.49 seconds\n",
      "3000/3405 -- 88.11% -- 3.89 seconds\n",
      "0/232 -- 0.00% -- 0.40 seconds\n",
      "0/232 -- 0.00% -- 0.40 seconds\n",
      "(3405, 384)\n",
      "(3405, 256)\n",
      "(3405,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kisumu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3483 -- 0.00% -- 0.70 seconds\n",
      "1000/3483 -- 28.71% -- 3.19 seconds\n",
      "2000/3483 -- 57.42% -- 2.76 seconds\n",
      "3000/3483 -- 86.13% -- 2.97 seconds\n",
      "0/3483 -- 0.00% -- 0.58 seconds\n",
      "1000/3483 -- 28.71% -- 3.85 seconds\n",
      "2000/3483 -- 57.42% -- 3.92 seconds\n",
      "3000/3483 -- 86.13% -- 4.12 seconds\n",
      "0/154 -- 0.00% -- 0.40 seconds\n",
      "0/154 -- 0.00% -- 0.40 seconds\n",
      "(3483, 384)\n",
      "(3483, 256)\n",
      "(3483,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kitui\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3586 -- 0.00% -- 0.73 seconds\n",
      "1000/3586 -- 27.89% -- 3.26 seconds\n",
      "2000/3586 -- 55.77% -- 2.81 seconds\n",
      "3000/3586 -- 83.66% -- 2.73 seconds\n",
      "0/3586 -- 0.00% -- 0.67 seconds\n",
      "1000/3586 -- 27.89% -- 3.81 seconds\n",
      "2000/3586 -- 55.77% -- 4.16 seconds\n",
      "3000/3586 -- 83.66% -- 3.87 seconds\n",
      "0/51 -- 0.00% -- 0.46 seconds\n",
      "0/51 -- 0.00% -- 0.44 seconds\n",
      "(3586, 384)\n",
      "(3586, 256)\n",
      "(3586,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machakos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3451 -- 0.00% -- 0.71 seconds\n",
      "1000/3451 -- 28.98% -- 3.16 seconds\n",
      "2000/3451 -- 57.95% -- 2.94 seconds\n",
      "3000/3451 -- 86.93% -- 2.89 seconds\n",
      "0/3451 -- 0.00% -- 0.59 seconds\n",
      "1000/3451 -- 28.98% -- 4.23 seconds\n",
      "2000/3451 -- 57.95% -- 3.76 seconds\n",
      "3000/3451 -- 86.93% -- 3.82 seconds\n",
      "0/186 -- 0.00% -- 0.43 seconds\n",
      "0/186 -- 0.00% -- 0.47 seconds\n",
      "(3451, 384)\n",
      "(3451, 256)\n",
      "(3451,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malindi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3454 -- 0.00% -- 0.48 seconds\n",
      "1000/3454 -- 28.95% -- 3.15 seconds\n",
      "2000/3454 -- 57.90% -- 2.76 seconds\n",
      "3000/3454 -- 86.86% -- 2.75 seconds\n",
      "0/3454 -- 0.00% -- 0.51 seconds\n",
      "1000/3454 -- 28.95% -- 3.83 seconds\n",
      "2000/3454 -- 57.90% -- 3.64 seconds\n",
      "3000/3454 -- 86.86% -- 3.76 seconds\n",
      "0/183 -- 0.00% -- 0.38 seconds\n",
      "0/183 -- 0.00% -- 0.36 seconds\n",
      "(3454, 384)\n",
      "(3454, 256)\n",
      "(3454,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mombasa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3313 -- 0.00% -- 0.61 seconds\n",
      "1000/3313 -- 30.18% -- 3.13 seconds\n",
      "2000/3313 -- 60.37% -- 2.82 seconds\n",
      "3000/3313 -- 90.55% -- 2.82 seconds\n",
      "0/3313 -- 0.00% -- 0.66 seconds\n",
      "1000/3313 -- 30.18% -- 3.89 seconds\n",
      "2000/3313 -- 60.37% -- 3.73 seconds\n",
      "3000/3313 -- 90.55% -- 4.16 seconds\n",
      "0/324 -- 0.00% -- 0.46 seconds\n",
      "0/324 -- 0.00% -- 0.43 seconds\n",
      "(3313, 384)\n",
      "(3313, 256)\n",
      "(3313,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nairobi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3289 -- 0.00% -- 0.80 seconds\n",
      "1000/3289 -- 30.40% -- 2.97 seconds\n",
      "2000/3289 -- 60.81% -- 3.04 seconds\n",
      "3000/3289 -- 91.21% -- 2.83 seconds\n",
      "0/3289 -- 0.00% -- 1.07 seconds\n",
      "1000/3289 -- 30.40% -- 3.80 seconds\n",
      "2000/3289 -- 60.81% -- 3.46 seconds\n",
      "3000/3289 -- 91.21% -- 4.26 seconds\n",
      "0/348 -- 0.00% -- 0.40 seconds\n",
      "0/348 -- 0.00% -- 0.41 seconds\n",
      "(3289, 384)\n",
      "(3289, 256)\n",
      "(3289,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 17 is smaller than n_iter=20. Running 17 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naivasha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3555 -- 0.00% -- 0.67 seconds\n",
      "1000/3555 -- 28.13% -- 3.18 seconds\n",
      "2000/3555 -- 56.26% -- 2.89 seconds\n",
      "3000/3555 -- 84.39% -- 2.73 seconds\n",
      "0/3555 -- 0.00% -- 0.64 seconds\n",
      "1000/3555 -- 28.13% -- 4.03 seconds\n",
      "2000/3555 -- 56.26% -- 4.12 seconds\n",
      "3000/3555 -- 84.39% -- 3.85 seconds\n",
      "0/82 -- 0.00% -- 0.41 seconds\n"
     ]
    }
   ],
   "source": [
    "# use points from df3 to match the search urls in the sentinal or landsat datasat\n",
    "points = df3[[\"lon\", \"lat\"]].to_numpy()\n",
    "houseprice_log = np.log10(df3[\"houseprice\"].to_numpy() + 1)\n",
    "\n",
    "# Create a group array based on the \"city\" column\n",
    "groups = df3[\"City\"].to_numpy()\n",
    "\n",
    "# Perform leave-one-city-out splitting\n",
    "logo = LeaveOneGroupOut()\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "group_scores = {}\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_distributions = {\n",
    "    'alpha': np.logspace(-8, 8, base=10, num=17),\n",
    "    'solver': ['auto']\n",
    "}\n",
    "\n",
    "for train_indices, test_indices in logo.split(points, groups=groups):\n",
    "    train_sets.append(train_indices)\n",
    "    test_sets.append(test_indices)\n",
    "    city = groups[test_indices[0]]\n",
    "    print(city)\n",
    "    \n",
    "    train_dataset1 = CustomDataset(points[train_indices], [matching_nir[idx] for idx in train_indices])\n",
    "    test_dataset1 = CustomDataset(points[test_indices], [matching_nir[idx] for idx in train_indices])\n",
    "    \n",
    "    train_dataset2 = CustomDataset(points[train_indices], [matching_urls[idx] for idx in train_indices])\n",
    "    test_dataset2 = CustomDataset(points[test_indices], [matching_urls[idx] for idx in train_indices])\n",
    "    \n",
    "    model1 = RCF(num_features=128, num_input_channels=1).eval().to(device) \n",
    "    model2 = RCF(num_features=256, num_input_channels=3).eval().to(device)\n",
    "    # Extract features from CustomDataset for train and test datasets: x_train1 for the nir, x_train2 for the rgb, x_train3 for the extracted lightnight\n",
    "    x_train1 = extract_features(train_dataset1,model1,num_features=128)\n",
    "    x_train2 = extract_features(train_dataset2,model2,num_features=256)\n",
    "    x_train3 = df4.iloc[train_indices]\n",
    "    \n",
    "    x_test1 = extract_features(test_dataset1, model1,num_features=128)\n",
    "    x_test2 = extract_features(test_dataset2, model2,num_features=256)\n",
    "    x_test3 = df4.iloc[test_indices]\n",
    "    \n",
    "    # Add nightlight_log to the training set\n",
    "    x_train = np.concatenate((x_train1,x_train2), axis=1)\n",
    "    print(x_train.shape)\n",
    "    #x_train[np.isinf(x_train)] = 0\n",
    "    x_test = np.concatenate((x_test1,x_test2), axis=1)\n",
    "    #x_test[np.isinf(x_test)] = 0\n",
    "\n",
    "    y_train = houseprice_log.copy()[train_indices]\n",
    "    y_test = houseprice_log.copy()[test_indices]\n",
    "    print(x_train2.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    # Perform random search for hyperparameter tuning\n",
    "    ridge = Ridge()\n",
    "    ridge_random = RandomizedSearchCV(ridge, param_distributions, cv=5, n_iter=20, random_state=42)\n",
    "    ridge_random.fit(x_train, y_train)\n",
    "    \n",
    "    # Get the best hyperparameters\n",
    "    best_alpha = ridge_random.best_params_['alpha']\n",
    "    best_solver = ridge_random.best_params_['solver']\n",
    "    \n",
    "    # Initialize Ridge Regression with the best hyperparameters\n",
    "    ridge_cv_best = Ridge(alpha=best_alpha, solver=best_solver)\n",
    "    ridge_cv_best.fit(x_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the test dataset\n",
    "    test_predictions = ridge_cv_best.predict(x_test)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    test_score = r2_score(y_test, test_predictions)\n",
    "    \n",
    "    # Calculate the train score on the current city group\n",
    "    train_predictions = ridge_cv_best.predict(x_train)\n",
    "    train_mse = mean_squared_error(y_train, train_predictions)\n",
    "    train_score = r2_score(y_train, train_predictions)\n",
    "    \n",
    "    # Store the test score and train score for the current city group\n",
    "    group_scores[city] = {'train_score': train_score, 'train_mse':train_mse,'test_score': test_score, 'test_mse':test_mse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa992b-a5a7-4ef0-a39c-32cc625636d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the evaluation scores for each city group\n",
    "for city, score in group_scores.items():\n",
    "    print(f\"City: {city}, Test Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e962164-32d1-4d26-ae68-a90d60d6c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(group_scores,  orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e9cb6-8555-49e4-a06e-d2babb1047ea",
   "metadata": {},
   "source": [
    "# Full datasset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed86013",
   "metadata": {},
   "source": [
    "This part provide the full dataser for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9d43f-3306-49b9-a5e2-453853fa93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(points, matching_urls)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=os.cpu_count() * 2,\n",
    "    collate_fn=lambda x: x,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb949635-62ea-41a9-8ff4-d6d50d50b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = np.zeros((points.shape[0], num_features), dtype=float)\n",
    "\n",
    "tic = time.time()\n",
    "i = 0\n",
    "for images in dataloader:\n",
    "    for image in images:\n",
    "\n",
    "        if image is not None:\n",
    "            # A full image should be ~101x101 pixels (i.e. ~1km^2 at a 10m/px spatial\n",
    "            # resolution), however we can receive smaller images if an input point\n",
    "            # happens to be at the edge of a S2 scene (a literal edge case). To deal\n",
    "            # with these (edge) cases we crudely drop all images where the spatial\n",
    "            # dimensions aren't both greater than 20 pixels.\n",
    "            if image.shape[1] >= 20 and image.shape[2] >= 20:\n",
    "                image = image.to(device)\n",
    "                with torch.no_grad():\n",
    "                    feats = model(image.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "                x_all[i] = feats\n",
    "            else:\n",
    "                # this happens if the point is close to the edge of a scene\n",
    "                # (one or both of the spatial dimensions of the image are very small)\n",
    "                pass\n",
    "        else:\n",
    "            pass  # this happens if we do not find a S2 scene for some point\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\n",
    "                f\"{i}/{points.shape[0]} -- {i / points.shape[0] * 100:0.2f}%\"\n",
    "                + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "            )\n",
    "            tic = time.time()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2e339-0c44-4007-9180-e2538054ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = houseprice_log.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e6198-fd42-4ea1-93a7-163c815ce9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nofeature_mask = ~(x_all.sum(axis=1) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758e2d3-42b2-411f-8134-4144cb322b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4e9c4-a7cb-4a17-8b97-16d583c4c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = x_all[nofeature_mask]\n",
    "y_all = y_all[nofeature_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488e706-55f8-49a6-8ff4-35d091941c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de700c97-343c-4424-be11-667032d45ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_all, y_all, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086fac8-854b-4b93-a930-848daeb92b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_random = RidgeCV(cv=5, alphas=np.logspace(-8, 8, base=10, num=17))\n",
    "ridge_cv_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3821aca-9086-4769-bdf2-40f5d176570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation R2 performance {ridge_cv_random.best_score_:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f00eaf-b841-4aae-a8bd-df71835f7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv_random.predict(x_test), 0)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, y_test, alpha=0.2, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.title(r\"$\\log_{10}(1 + $houseprice$)$\", fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.xlim([0, 6])\n",
    "plt.ylim([0, 6])\n",
    "\n",
    "plt.text(\n",
    "    0.5,\n",
    "    5,\n",
    "    s=\"R$^2$ = %0.2f\" % (r2_score(y_test, y_pred)),\n",
    "    fontsize=15,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "m, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, m * y_pred + b, color=\"black\")\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d78bcbe-c71f-4fa4-977f-051366ddce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b50f8d-3fc7-4020-a42b-d834c536293d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Perform OLS regression on the whole dataset\n",
    "x_train = sm.add_constant(x_train)  # Add constant term for the intercept\n",
    "ols_model = sm.OLS(y_train, x_train)\n",
    "ols_results = ols_model.fit()\n",
    "\n",
    "# Get the summary tables\n",
    "summary_tables = ols_results.summary().tables\n",
    "\n",
    "# Print the upper part of the OLS Regression Results\n",
    "print(summary_tables[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c1243-68c1-44cf-af7e-0e126b02f2b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Perform OLS regression on the whole dataset\n",
    "x_test = sm.add_constant(x_test)  # Add constant term for the intercept\n",
    "ols_model = sm.OLS(y_test, x_test)\n",
    "ols_results = ols_model.fit()\n",
    "\n",
    "# Get the summary tables\n",
    "summary_tables = ols_results.summary().tables\n",
    "\n",
    "# Print the upper part of the OLS Regression Results\n",
    "print(summary_tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189d458-0535-4953-aca9-730212215935",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = points[nofeature_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efc941-cfe7-4d84-ad91-f92dec1523eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lon = np.percentile(points[:, 0], 80)\n",
    "train_idxs = np.where(points[:, 0] <= split_lon)[0]\n",
    "test_idxs = np.where(points[:, 0] > split_lon)[0]\n",
    "\n",
    "x_train = x_all[train_idxs]\n",
    "x_test = x_all[test_idxs]\n",
    "y_train = y_all[train_idxs]\n",
    "y_test = y_all[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f08a5-0e1a-4b2e-b94a-5ab02314e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(points[:, 0], points[:, 1], c=y_all, s=1)\n",
    "plt.vlines(\n",
    "    split_lon,\n",
    "    ymin=points[:, 1].min(),\n",
    "    ymax=points[:, 1].max(),\n",
    "    color=\"black\",\n",
    "    linewidth=4,\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfdd78b-8175-452b-8b11-7699a97a18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(cv=5, alphas=np.logspace(-8, 8, base=10, num=17))\n",
    "ridge_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bdde4-7e58-42e4-b63e-2cfc96aa1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation R2 performance {ridge_cv.best_score_:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad114444-84ec-4870-a5f5-58ff5efbabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv.predict(x_test), 0)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, y_test, alpha=0.2, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.title(r\"$\\log_{10}(1 + $people$/$km$^2)$\", fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.xlim([0, 6])\n",
    "plt.ylim([0, 6])\n",
    "\n",
    "plt.text(\n",
    "    0.5,\n",
    "    5,\n",
    "    s=\"R$^2$ = %0.2f\" % (r2_score(y_test, y_pred)),\n",
    "    fontsize=15,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "m, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, m * y_pred + b, color=\"black\")\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e5fb8-0a55-4904-9ece-36ad6fe87946",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346481c0-c82f-47c9-bace-400476729f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 5, num=50)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(y_train, bins=bins)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(r\"$\\log_{10}(1 + $people$/$km$^2)$\")\n",
    "plt.title(\"Train points -- western US\")\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(y_test, bins=bins)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(r\"$\\log_{10}(1 + $people$/$km$^2)$\")\n",
    "plt.title(\"Test points -- eastern US\")\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14962d99-f4b4-488b-9609-e67713672065",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(ridge_cv.predict(x_test), 0)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_pred, y_test, alpha=0.2, s=4)\n",
    "plt.xlabel(\"Predicted\", fontsize=15)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=15)\n",
    "plt.title(r\"$\\log_{10}(1 + $people$/$km$^2)$\", fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.xlim([0, 6])\n",
    "plt.ylim([0, 6])\n",
    "\n",
    "plt.text(\n",
    "    0.5,\n",
    "    5,\n",
    "    s=\"R$^2$ = %0.2f\" % (r2_score(y_test, y_pred)),\n",
    "    fontsize=15,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "m, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, m * y_pred + b, color=\"black\")\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
